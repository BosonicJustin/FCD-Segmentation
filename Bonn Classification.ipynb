{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using deivce: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.visualize_nii import visualize_mri_sample\n",
    "from data.bonn_data import BonnMRIClassificationDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.classifier import FCDDetector\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model = FCDDetector()\n",
    "\n",
    "data = BonnMRIClassificationDataset('./Dataset')\n",
    "\n",
    "sample = data[0]\n",
    "\n",
    "model.encoder(sample['FLAIR'].unsqueeze(0).float())\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Using deivce:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406eb50",
   "metadata": {},
   "source": [
    "Initially we will overfit to a small dataset to see if the model has enough capacity to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef6d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30],  Train Loss: 0.7381\n",
      "Accuracy: 0.6000, Precision: 0.6000, Recall: 1.0000\n",
      "Epoch [2/30],  Train Loss: 0.7252\n",
      "Accuracy: 0.6000, Precision: 0.6000, Recall: 1.0000\n",
      "Epoch [3/30],  Train Loss: 0.7139\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m false_negatives = \u001b[32m0\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFLAIR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/data/bonn_data.py:112\u001b[39m, in \u001b[36mOverfittingDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx > \u001b[38;5;28mself\u001b[39m.num_samples:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIndex out of range for the overfitting dataset.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbonn_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/data/bonn_data.py:83\u001b[39m, in \u001b[36mBonnMRIClassificationDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Binary label: 1 if ROI contains any positive voxels, else 0\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m roi_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     roi_img = \u001b[43mnib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     label = torch.tensor(\u001b[38;5;28mint\u001b[39m(roi_img.any()), dtype=torch.long)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/dataobj_images.py:374\u001b[39m, in \u001b[36mDataobjImage.get_fdata\u001b[39m\u001b[34m(self, caching, dtype)\u001b[39m\n\u001b[32m    370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fdata_cache\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m caching == \u001b[33m'\u001b[39m\u001b[33mfill\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mself\u001b[39m._fdata_cache = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/arrayproxy.py:454\u001b[39m, in \u001b[36mArrayProxy.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    434\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m    436\u001b[39m \u001b[33;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m \u001b[33;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    456\u001b[39m         arr = arr.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/arrayproxy.py:421\u001b[39m, in \u001b[36mArrayProxy._get_scaled\u001b[39m\u001b[34m(self, dtype, slicer)\u001b[39m\n\u001b[32m    419\u001b[39m     scl_inter = scl_inter.astype(use_dtype)\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m scaled = apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    423\u001b[39m     scaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/arrayproxy.py:391\u001b[39m, in \u001b[36mArrayProxy._get_unscaled\u001b[39m\u001b[34m(self, slicer)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m._shape, \u001b[38;5;28;01mFalse\u001b[39;00m) == canonical_slicers(\n\u001b[32m    388\u001b[39m     (), \u001b[38;5;28mself\u001b[39m._shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    389\u001b[39m ):\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[32m    401\u001b[39m         fileobj,\n\u001b[32m    402\u001b[39m         slicer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    407\u001b[39m         lock=\u001b[38;5;28mself\u001b[39m._lock,\n\u001b[32m    408\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/volumeutils.py:467\u001b[39m, in \u001b[36marray_from_file\u001b[39m\u001b[34m(shape, in_dtype, infile, offset, order, mmap)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[33m'\u001b[39m\u001b[33mreadinto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    466\u001b[39m     data_bytes = \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     n_read = \u001b[43minfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m     needs_copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/gzip.py:338\u001b[39m, in \u001b[36mGzipFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merrno\u001b[39;00m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno.EBADF, \u001b[33m\"\u001b[39m\u001b[33mread() on write-only GzipFile object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/_compression.py:67\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmemoryview\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from data.bonn_data import OverfittingDataset\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss with logits\n",
    "\n",
    "num_of_overfitting_samples = 10\n",
    "\n",
    "overfitting_dataset = OverfittingDataset(bonn_dataset=data, num_samples=num_of_overfitting_samples)\n",
    "\n",
    "train_loader = DataLoader(overfitting_dataset, batch_size=num_of_overfitting_samples, shuffle=False)\n",
    "\n",
    "num_epochs = 30  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "            inputs = batch['FLAIR'].float()  # Input MRI data\n",
    "            labels = batch['label'].float()  # Corresponding labels (convert to float for BCEWithLogitsLoss)\n",
    "\n",
    "            # Move data to GPU if available\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                model = model.cuda()\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \", f\"Train Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['FLAIR'].float()\n",
    "            labels = batch['label'].float()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            true_positives += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            false_positives += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m model.train()\n\u001b[32m     34\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFLAIR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input MRI data\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Corresponding labels (convert to float for BCEWithLogitsLoss)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/data/bonn_data.py:78\u001b[39m, in \u001b[36mBonnMRIClassificationDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     75\u001b[39m roi_path = roi_files[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m roi_files \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Load FLAIR image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m flair_img = \u001b[43mnib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflair_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m flair_tensor = torch.from_numpy(flair_img).float().unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Binary label: 1 if ROI contains any positive voxels, else 0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/dataobj_images.py:374\u001b[39m, in \u001b[36mDataobjImage.get_fdata\u001b[39m\u001b[34m(self, caching, dtype)\u001b[39m\n\u001b[32m    370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fdata_cache\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m caching == \u001b[33m'\u001b[39m\u001b[33mfill\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mself\u001b[39m._fdata_cache = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/arrayproxy.py:454\u001b[39m, in \u001b[36mArrayProxy.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    434\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m    436\u001b[39m \u001b[33;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m \u001b[33;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    456\u001b[39m         arr = arr.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/arrayproxy.py:421\u001b[39m, in \u001b[36mArrayProxy._get_scaled\u001b[39m\u001b[34m(self, dtype, slicer)\u001b[39m\n\u001b[32m    419\u001b[39m     scl_inter = scl_inter.astype(use_dtype)\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m scaled = \u001b[43mapply_read_scaling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscl_slope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscl_inter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    423\u001b[39m     scaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MRI/FCD-Segmentation/.pixi/envs/default/lib/python3.12/site-packages/nibabel/volumeutils.py:928\u001b[39m, in \u001b[36mapply_read_scaling\u001b[39m\u001b[34m(arr, slope, inter)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inter1d != \u001b[32m0.0\u001b[39m:\n\u001b[32m    927\u001b[39m     arr = arr + inter1d\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss with logits\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "train_data, val_data = random_split(data, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for train and validation datasets\n",
    "batch_size = 20  # Define batch size\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=val_size, shuffle=False)\n",
    "\n",
    "# Initialize lists to store loss information\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Collect precision, recall, and validation accuracy for each epoch\n",
    "precisions = []\n",
    "recalls = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Print all the labels in the validation loader\n",
    "for val_batch in val_loader:\n",
    "    print(val_batch['label'])\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 30  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['FLAIR'].float()  # Input MRI data\n",
    "        labels = batch['label'].float()  # Corresponding labels (convert to float for BCEWithLogitsLoss)\n",
    "\n",
    "        # Move data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_inputs = val_batch['FLAIR'].float()\n",
    "            val_labels = val_batch['label'].float()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                val_inputs = val_inputs.cuda()\n",
    "                val_labels = val_labels.cuda()\n",
    "\n",
    "            val_outputs = model(val_inputs).squeeze(1)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = (torch.sigmoid(val_outputs) > 0.5).float()\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "            total_predictions += val_labels.size(0)\n",
    "\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    true_positives = ((predicted == 1) & (val_labels == 1)).sum().item()\n",
    "    false_positives = ((predicted == 1) & (val_labels == 0)).sum().item()\n",
    "    false_negatives = ((predicted == 0) & (val_labels == 1)).sum().item()\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "    # Store losses\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    # Print epoch loss and accuracy\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Validation Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}, \"\n",
    "          f\"Precision: {precision:.4f}, \"\n",
    "          f\"Recall: {recall:.4f}\"\n",
    "    )\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Precision, Recall, and Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), precisions, label='Precision')\n",
    "plt.plot(range(1, num_epochs + 1), recalls, label='Recall')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Precision, Recall, and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cce20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
